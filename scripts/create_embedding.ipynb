{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016a2821-98b9-48ea-8039-3d1bf7590c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from momentfm import MOMENTPipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import gc\n",
    "from tqdm import trange\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bd0e98-b829-4c54-9298-6406ec0ce864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4da31a-e0fe-42db-aa9e-47728b49e1c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MOMENTPipeline(\n",
       "  (normalizer): RevIN()\n",
       "  (tokenizer): Patching()\n",
       "  (patch_embedding): PatchEmbedding(\n",
       "    (value_embedding): Linear(in_features=8, out_features=1024, bias=False)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={\"task_name\":\"embedding\"}\n",
    ")\n",
    "model.init()\n",
    "model.to(\"cuda\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7547284c-2fb2-4a86-a214-248fe29658b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(646595, 111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/316 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████| 316/316 [9:00:23<00:00, 102.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238789, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/117 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████| 117/117 [4:37:15<00:00, 142.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079197, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/527 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████| 527/527 [1:44:27<00:00, 11.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621381, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/304 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████| 304/304 [3:55:14<00:00, 46.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076316, 106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/526 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████| 526/526 [2:33:43<00:00, 17.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939419, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/459 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████| 459/459 [12:40:52<00:00, 99.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(635546, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/311 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████| 311/311 [2:04:36<00:00, 24.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454541, 111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/222 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████| 222/222 [11:07:01<00:00, 180.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664797, 111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/325 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      " 11%|██████▉                                                        | 36/325 [16:51:30<135:20:10, 1685.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     34\u001b[39m     out = model(x_enc=chunk, input_mask=chunk_mask)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     embeddings = out.embeddings.cpu()\n\u001b[32m     36\u001b[39m     all_embeddings.append(embeddings)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m chunk, chunk_mask, out, embeddings\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "root_dir = \"numpy_data\"\n",
    "embedding_result = []\n",
    "\n",
    "\n",
    "for file in os.listdir(root_dir):\n",
    "    if file.endswith(\".npy\"):\n",
    "        data = np.load(f\"{root_dir}/{file}\")\n",
    "        print(data.shape)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    data = data.T.unsqueeze(0)\n",
    "\n",
    "    chunk_size = 2048\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for start in trange(0, data.shape[2], chunk_size):\n",
    "        end = min(start + chunk_size, data.shape[2])\n",
    "        chunk = data[:, :, start:end].to(\"cuda\")\n",
    "        chunk_mask = torch.ones(\n",
    "            chunk.shape[0],\n",
    "            chunk.shape[2],\n",
    "            dtype=bool, \n",
    "            device=\"cuda\"\n",
    "        )\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            out = model(x_enc=chunk, input_mask=chunk_mask)\n",
    "            embeddings = out.embeddings.cpu()\n",
    "            all_embeddings.append(embeddings)\n",
    "    \n",
    "        del chunk, chunk_mask, out, embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    final_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    embedding = final_embeddings.mean(dim=0)\n",
    "    embedding_result.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9ae9e-4d50-42d6-b2d0-7405eaf62d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190d85ec-4b66-4e58-b054-e24ea3a1c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/sklearn/utils/extmath.py:1144: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/sklearn/utils/extmath.py:1149: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342253, 114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/sklearn/utils/extmath.py:1169: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([            nan,             nan,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan, -1.73199785e+00, -2.30951043e+00, -9.12217532e-01,\n",
       "        2.42223508e+00,  3.73200231e+00,  3.73200374e+00,  3.73199964e+00,\n",
       "       -1.57181192e-01, -1.56019127e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.00538548e+00,\n",
       "       -3.50988703e-04, -7.61977717e-03,  4.59955245e-04, -8.68003631e-04,\n",
       "        3.20741060e-04, -5.07723607e-04,  4.16904455e-04,  8.49254713e-04,\n",
       "       -3.67864006e-04,  8.61330443e-04,  1.53034703e-03, -2.95979594e-03,\n",
       "       -1.26289351e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -4.85893589e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.03587053e+00,\n",
       "       -3.82755801e-02, -1.73159928e+00, -3.45718056e-01, -2.46876873e-01,\n",
       "       -5.28846080e-01, -4.57348163e-03, -2.69587671e-02,  7.77639418e-03,\n",
       "       -4.21381127e+00, -7.55955905e-01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "print(data.shape)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc538eb-a741-4ad8-ab19-85e58a217676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MOMENTPipeline(\n",
       "  (normalizer): RevIN()\n",
       "  (tokenizer): Patching()\n",
       "  (patch_embedding): PatchEmbedding(\n",
       "    (value_embedding): Linear(in_features=8, out_features=1024, bias=False)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={\"task_name\":\"embedding\"}\n",
    ")\n",
    "model.init()\n",
    "model.to(\"cuda\").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aabcbec1-8cec-4de0-98a8-63496a2d44fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 114, 342253])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(data, np.ndarray):\n",
    "    data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd1f70-8735-4159-89d7-25da2052a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mask = ~torch.isnan(data)\n",
    "\n",
    "print(input_mask.shape)\n",
    "input_mask[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728d629-5907-4372-b318-fcc2c128d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.T.unsqueeze(0) # since for MOMENT the data has to be [batch, features, sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493be92d-f4fd-458a-8cc9-b6cd74310ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in trange(10, desc=\"Processing\"):\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c7d0244-7590-4cb3-957e-f1ff0147cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/168 [00:00<?, ?it/s]/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/giriczvince/miniconda3/envs/moment/lib/python3.11/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████| 168/168 [1:32:42<00:00, 33.11s/it]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 2048\n",
    "all_embeddings = []\n",
    "\n",
    "for start in trange(0, data.shape[2], chunk_size):\n",
    "    end = min(start + chunk_size, data.shape[2])\n",
    "    chunk = data[:, :, start:end].to(\"cuda\")\n",
    "    chunk_mask = torch.ones(\n",
    "        chunk.shape[0],\n",
    "        chunk.shape[2],\n",
    "        dtype=bool, \n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(x_enc=chunk, input_mask=chunk_mask)\n",
    "        embeddings = out.embeddings.cpu()\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "    del chunk, chunk_mask, out, embeddings\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "final_embeddings = torch.cat(all_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e52d36ff-3e21-44a4-bfff-a399e73a3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(final_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbf2ac0e-de29-4b3d-a76a-fc0ab1c19c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = final_embeddings.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590aee34-462d-4b07-ada0-d8bdd75cb13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0539,  0.0247, -0.0401, -0.0558,  0.0312, -0.0448,  0.0739, -0.1524,\n",
       "        -0.0823,  0.0532, -0.1173, -0.0902, -0.0508, -0.0389,  0.0307])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56521da-0a02-4241-80f5-0fc86fd35ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11_moment",
   "language": "python",
   "name": "moment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
