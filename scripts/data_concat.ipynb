{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17226581-014e-435b-ac0b-6c2f303df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "029a72df-800b-4752-84cd-4a56f057291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path, excluded_files):\n",
    "    dataframes = [\n",
    "    pd.read_csv(f\"{data_path}/{csv}\", on_bad_lines='skip') \n",
    "    for csv in os.listdir(data_path) \n",
    "    if csv not in excluded_files\n",
    "            ]\n",
    "    names = [\n",
    "        csv \n",
    "        for csv in os.listdir(data_path)\n",
    "        if csv not in excluded_files\n",
    "            ]\n",
    "    return dataframes, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "385f97fe-bfe9-4f3c-b524-d03d9943ba45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed/2025_06_17_14_29_felvetel:\n",
      "uncompressed/2025_06_20_10_44_felvetel:\n",
      "uncompressed/2025_05_30_15_15_felvetel:\n",
      "uncompressed/2025_06_13_13_12_felvetel:\n",
      "uncompressed/2025_07_09_11_00_felvetel:\n",
      "uncompressed/2025_06_16_13_18_felvetel:\n",
      "uncompressed/2025_07_10_13_40_felvetel:\n",
      "uncompressed/2025_07_09_09_00_felvetel:\n",
      "uncompressed/2025_05_16_felvetel:\n",
      "uncompressed/2025_06_16_14_41_felvetel:\n",
      "uncompressed/2025_05_29_10_30_2_felvetel:\n",
      "uncompressed/2025_05_29_10_30_felvetel:\n",
      "uncompressed/2025_07_09_14_00_felvetel:\n",
      "uncompressed/2025_07_10_14_00_felvetel:\n",
      "uncompressed/2025_07_09_13_30_felvetel:\n",
      "uncompressed/2025_04_16_felvetel:\n",
      "uncompressed/2025_05_20_15_00_felvetel:\n",
      "uncompressed/2025_05_30_14_50_felvetel:\n",
      "uncompressed/2025_06_13_12_43_felvetel:\n",
      "uncompressed/2025_06_16_13_46_felvetel:\n",
      "uncompressed/2025_06_11_14_30_felvetel:\n",
      "uncompressed/2025_05_20_12_30_felvetel:\n",
      "uncompressed/2025_06_10_15_10_felvetel:\n",
      "uncompressed/2025_06_13_12_13_felvetel:\n",
      "uncompressed/2025_05_28_14_00_felvetel:\n",
      "uncompressed/2025_06_06_felvetel:\n",
      "uncompressed/2025_07_09_11_40_felvetel:\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(\"uncompressed\")\n",
    "excluded_files = {\"info.csv\"}\n",
    "\n",
    "for directory in root_dir.iterdir():\n",
    "    if directory.is_dir():\n",
    "        try:\n",
    "            print(root_dir.name + \"/\" + directory.name + \":\")\n",
    "            dataframes, names = read_data(root_dir.name + \"/\" + directory.name, excluded_files)\n",
    "            \n",
    "            # print(\"Shapes:\")\n",
    "            # for df in dataframes:\n",
    "            #     print(df.shape)\n",
    "            \n",
    "            # print(\"\\nFile names:\")\n",
    "            # print(names)\n",
    "            # print()\n",
    "\n",
    "            max_len = max(df.shape[0] for df in dataframes)\n",
    "            # print(max_len)\n",
    "\n",
    "            padded = []\n",
    "            for df in dataframes:\n",
    "                numeric_df = df.select_dtypes(include=[np.number])\n",
    "                arr = numeric_df.to_numpy(dtype=float)\n",
    "                padded.append(\n",
    "                    np.pad(\n",
    "                        arr, \n",
    "                        pad_width = ((0, max_len - arr.shape[0]), (0, 0)),\n",
    "                        mode = \"constant\",\n",
    "                        constant_values = np.nan\n",
    "                    )\n",
    "                )\n",
    "            # print(len(padded), padded[0].shape)\n",
    "\n",
    "            combined_array = np.concatenate(padded, axis=1)\n",
    "\n",
    "            np.save(f\"numpy_data/{directory.name}.npy\", combined_array)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: 'expot_adatok' not found in {directory.name}\")\n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ae879-53d2-4290-89d3-f56ea644a57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11_moment",
   "language": "python",
   "name": "moment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
